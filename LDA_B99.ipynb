{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3/Sa3PwB/jkZCiTV/z1kI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystal-zhu/Sitcom_Success_Factors-CSDS_312/blob/main/LDA_B99.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yvn7galABjVu"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(400)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/crystal-zhu/Sitcom_Success_Factors-CSDS_312/main/B99_Analysis/data/B99_Script/Brooklyn99_Season1-4_Dataset.csv\"\n",
        "response = requests.get(url)\n",
        "\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    with open(\"Brooklyn99_Season1-4_Dataset\", \"w\") as f:\n",
        "        f.write(response.text)\n",
        "    print(\"CSV file downloaded successfully\")\n",
        "else:\n",
        "    print(\"Failed to download CSV file. Status code:\", response.status_code)\n",
        "\n",
        "lines = pd.read_csv(\"Brooklyn99_Season1-4_Dataset\")['line']\n"
      ],
      "metadata": {
        "id": "sEfh1EnpBmy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92699e80-7345-4de1-a3a7-b49d36d99649"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file downloaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# def filter_adjectives(text):\n",
        "#     tagged_words = pos_tag(word_tokenize(text))\n",
        "#     filtered_words = [word for word, tag in tagged_words if tag not in ['JJ', 'JJR', 'JJS']]  # 'JJ': Adjective, 'JJR': Comparative adjective, 'JJS': Superlative adjective\n",
        "#     return ' '.join(filtered_words)\n",
        "\n",
        "# # Example usage\n",
        "# # text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "# # filtered_text = filter_adjectives(text)\n",
        "# # print(filtered_text)  # Output: \"quick brown jumps over lazy\"\n",
        "\n",
        "\n",
        "\n",
        "# filter_adjectives_lines\n",
        "# lines[90]\n",
        "\n",
        "\n",
        "def keep_only_content_words(s):\n",
        "    processed = nlp(s)\n",
        "    # result = [token.lemma_ for token in processed if token.pos_ in ('NOUN', 'VERB', 'ADJ', 'ADV', 'X', 'DET')]\n",
        "    result = [token.lemma_ for token in processed if token.pos_ in ('NOUN', 'VERB','DET')]\n",
        "\n",
        "    return ' '.join(result)\n",
        "\n",
        "def keep_only_content_words_all():\n",
        "  for index in range[0:len(lines)]:\n",
        "    lines[index] = keep_only_content_words(lines[index])\n",
        "\n",
        "# sample_line = lines[140]\n",
        "# print(sample_line)\n",
        "# print(keep_only_content_words(sample_line))\n",
        "# print(preprocess(keep_only_content_words(sample_line)))\n",
        "\n",
        "lines[0:50]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hTG9-OzC8cR",
        "outputId": "f901aa32-1a31-4ef3-c224-8438bdea315a"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      This job is eating me alive. I can't breathe ...\n",
              "1                      Hey! What are you doing, weirdo?\n",
              "2      I'm doing the best speech from Donnie Brasco....\n",
              "3                           Get it together, man. Okay?\n",
              "4      So the store was hit about two hours ago. The...\n",
              "5                                                Sorry.\n",
              "6      I'd like a list of all your employees, whoeve...\n",
              "7      Uh, Detective... I already solved the case. W...\n",
              "8                             And how do you know that?\n",
              "9      I had an informant on the inside. He's been h...\n",
              "10     No, I got here five minutes before you and fi...\n",
              "11      I'm not sure if I can. I've been undercover ...\n",
              "12                                           All right.\n",
              "13         Detective Santiago! Don't walk away from me!\n",
              "14     Yes, I did crack the case. So, Santiago, woul...\n",
              "15                                         I hate this!\n",
              "16             Ah, yeah. And you're just gonna add one.\n",
              "17                                         I'm winning.\n",
              "18                                         I hate this!\n",
              "19      It's a good feeling. It's a good feeling. Yeah.\n",
              "20                             Enjoy it while it lasts.\n",
              "21                                              I will!\n",
              "22                 JP, update on the Morgenthau murder?\n",
              "23                                 I think it was flan.\n",
              "24     Charles thinks it was flan. I think it was bu...\n",
              "25     Maybe it was just old person gunk. You know h...\n",
              "26             Oldie gunk. Could be, yeah. Anyone else?\n",
              "27     How about we focus on the murder and not the ...\n",
              "28     Crime techs are at the scene now. We're headi...\n",
              "29     Okay, I want you on this. It's gonna be prior...\n",
              "30                 Wait, tell us about the new Captain.\n",
              "31     Captain Holt will be here soon. He'll wanna i...\n",
              "32     Hey, Gina. You know any scalpers? I wanna ask...\n",
              "33     Okay, two points to make here. First, Rihanna...\n",
              "34                      Yeah. What's your second point?\n",
              "35     She's got a type. Which is really anyone but ...\n",
              "36                Yeah, that was my ex-wife's type too.\n",
              "37     Look, a Rihanna concert's a pretty big swing,...\n",
              "38     Cool. Where would I find a place that shows o...\n",
              "39     Oh, yeah, just go on the Internet and search ...\n",
              "40                                    Great. Thank you.\n",
              "41                                              Good...\n",
              "42       Hey, you heard anything about the new Captain?\n",
              "43     Uh, no, and I don't care. I just wish Captain...\n",
              "44     He was terrible. You just liked him 'cause he...\n",
              "45                            On your marks, get set...\n",
              "46                What the hell's going on around here?\n",
              "47                Fire extinguisher roller chair derby?\n",
              "48                                                Okay.\n",
              "49                                              And go!\n",
              "Name: line, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming lines is a list of strings\n",
        "for i in range(len(lines)):\n",
        "    temp = lines[i]\n",
        "    new_line = temp[1:]  # Remove the first character\n",
        "    lines[i] = keep_only_content_words(new_line)\n",
        "\n",
        "\n",
        "lines[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xJ7Gr1psCWMf",
        "outputId": "be24594b-e3a6-4e1d-bd5f-32470341f13b"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have some bet get arrest this year the bet number go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfA6vICfCZNf",
        "outputId": "2a4c1d84-86a3-4b0d-af3b-3dfbd660efae"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(WordNetLemmatizer().lemmatize('went', pos = 'v')) # past tense to present tense"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nItiivZmCfEg",
        "outputId": "c89ba44e-141a-4cca-8dd9-677fe7675006"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"english\")\n",
        "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned',\n",
        "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational',\n",
        "           'traditional', 'reference', 'colonizer','plotted']\n",
        "singles = [stemmer.stem(plural) for plural in original_words]\n",
        "\n",
        "pd.DataFrame(data={'original word':original_words, 'stemmed':singles })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "Nh2ga36mDj7w",
        "outputId": "26b7013b-da8d-4f61-97d1-e46dd2f0a210"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   original word stemmed\n",
              "0       caresses  caress\n",
              "1          flies     fli\n",
              "2           dies     die\n",
              "3          mules    mule\n",
              "4         denied    deni\n",
              "5           died     die\n",
              "6         agreed    agre\n",
              "7          owned     own\n",
              "8        humbled   humbl\n",
              "9          sized    size\n",
              "10       meeting    meet\n",
              "11       stating   state\n",
              "12       siezing    siez\n",
              "13   itemization    item\n",
              "14   sensational  sensat\n",
              "15   traditional  tradit\n",
              "16     reference   refer\n",
              "17     colonizer   colon\n",
              "18       plotted    plot"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14a53e44-43ff-4895-b57b-c409824eb2d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original word</th>\n",
              "      <th>stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>caresses</td>\n",
              "      <td>caress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flies</td>\n",
              "      <td>fli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dies</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mules</td>\n",
              "      <td>mule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>denied</td>\n",
              "      <td>deni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>died</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>agreed</td>\n",
              "      <td>agre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>owned</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>humbled</td>\n",
              "      <td>humbl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sized</td>\n",
              "      <td>size</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>meeting</td>\n",
              "      <td>meet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>stating</td>\n",
              "      <td>state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>siezing</td>\n",
              "      <td>siez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>itemization</td>\n",
              "      <td>item</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sensational</td>\n",
              "      <td>sensat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>traditional</td>\n",
              "      <td>tradit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>reference</td>\n",
              "      <td>refer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>colonizer</td>\n",
              "      <td>colon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>plotted</td>\n",
              "      <td>plot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14a53e44-43ff-4895-b57b-c409824eb2d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14a53e44-43ff-4895-b57b-c409824eb2d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14a53e44-43ff-4895-b57b-c409824eb2d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a05f6b6-6866-43da-b47f-f232c3c0511c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a05f6b6-6866-43da-b47f-f232c3c0511c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a05f6b6-6866-43da-b47f-f232c3c0511c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"original word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"caresses\",\n          \"died\",\n          \"stating\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"caress\",\n          \"fli\",\n          \"size\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp\n"
      ],
      "metadata": {
        "id": "wQQA5rOwlo4U",
        "outputId": "41866fb0-90ec-4d0e-b1e0-7fc723653d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f2645b78cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            # TODO: Apply lemmatize_stemming() on the token, then add to the results list\n",
        "            result.append(lemmatize_stemming(token))\n",
        "\n",
        "    return result\n",
        "\n",
        "# filter_adjectives_lines\n",
        "# lines[100]\n",
        "# preprocess(lines[100])\n",
        "# # preprocess(lines[90])"
      ],
      "metadata": {
        "id": "sjmhdEqhCidh"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "VxBnKJtog9XF",
        "outputId": "a1ec06b2-722c-4976-d076-cf802a78abf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line_num = 200\n",
        "sample = lines[line_num]\n",
        "\n",
        "sample\n",
        "print(\"Original document: \")\n",
        "words = []\n",
        "for word in sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print(\"\\n\\nTokenized and lemmatized document: \")\n",
        "print(preprocess(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lvaq73AD7ps",
        "outputId": "8e0cce2d-1f12-4f8a-f7c8-33c25737a9f0"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original document: \n",
            "['think', 'study', 'drug']\n",
            "\n",
            "\n",
            "Tokenized and lemmatized document: \n",
            "['think', 'studi', 'drug']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: preprocess all the headlines, saving the list of results as 'processed_docs'\n",
        "processed_lines = lines.map(lambda x: preprocess(x))"
      ],
      "metadata": {
        "id": "SyJPVq5XFv0U"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwBVGSrNF2tv",
        "outputId": "f348c518-a20b-46e8-c3c9-fc39a71711ba"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                       [breath, spend, year]\n",
              "1                                    [weirdo]\n",
              "2             [speech, speech, stare, screen]\n",
              "3                                          []\n",
              "4       [store, hour, tablet, laptop, camera]\n",
              "                        ...                  \n",
              "6455                                   [mean]\n",
              "6456                                  [shift]\n",
              "6457                                       []\n",
              "6458                                       []\n",
              "6459                   [come, parti, tonight]\n",
              "Name: line, Length: 6460, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0WQCYlXPFvaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create a dictionary from 'processed_docs' containing the number of times a word appears\n",
        "in the training set using gensim.corpora.Dictionary and call it 'dictionary'\n",
        "'''\n",
        "dictionary = gensim.corpora.Dictionary(processed_lines)\n"
      ],
      "metadata": {
        "id": "nAc1woPpGFVP"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Checking dictionary created\n",
        "'''\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnxldMOwGOBS",
        "outputId": "d4a39fe8-e1c1-43a7-c5e2-2e246eb81df5"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 breath\n",
            "1 spend\n",
            "2 year\n",
            "3 weirdo\n",
            "4 screen\n",
            "5 speech\n",
            "6 stare\n",
            "7 camera\n",
            "8 hour\n",
            "9 laptop\n",
            "10 store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bi6pv0tGTNz",
        "outputId": "250c54a4-4419-46c8-9b7b-6346f771ab47"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary<2859 unique tokens: ['breath', 'spend', 'year', 'weirdo', 'screen']...>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "count = Counter()\n",
        "for doc in processed_lines:\n",
        "    for word in doc:\n",
        "        count[word]+=1\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Djd56ggGV19",
        "outputId": "d6d6b7f6-bd19-461a-dd2d-6f440407b749"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'know': 453, 'think': 298, 'look': 249, 'want': 238, 'tell': 195, 'time': 194, 'come': 193, 'work': 175, 'need': 172, 'thing': 131, 'thank': 131, 'case': 128, 'mean': 121, 'love': 117, 'talk': 116, 'wait': 100, 'like': 87, 'happen': 87, 'stop': 82, 'turn': 80, 'leav': 76, 'help': 74, 'feel': 69, 'plan': 68, 'hear': 66, 'life': 66, 'start': 63, 'place': 62, 'night': 59, 'hand': 56, 'peopl': 55, 'year': 54, 'minut': 52, 'face': 50, 'walk': 49, 'meet': 49, 'date': 49, 'break': 49, 'solv': 48, 'arrest': 48, 'hour': 47, 'detect': 47, 'offic': 47, 'captain': 45, 'believ': 45, 'kill': 45, 'head': 44, 'care': 44, 'shoot': 44, 'catch': 44, 'guess': 44, 'tonight': 43, 'point': 42, 'question': 42, 'hold': 41, 'wear': 41, 'sound': 41, 'problem': 41, 'phone': 41, 'friend': 40, 'watch': 39, 'steal': 39, 'crime': 39, 'pick': 39, 'file': 38, 'order': 38, 'listen': 38, 'stuff': 36, 'babi': 36, 'number': 36, 'read': 36, 'hate': 35, 'idea': 35, 'word': 34, 'desk': 34, 'report': 34, 'butt': 34, 'sign': 34, 'pizza': 33, 'pull': 33, 'shift': 33, 'lose': 32, 'check': 32, 'week': 32, 'team': 32, 'polic': 32, 'stay': 32, 'room': 31, 'drug': 31, 'drink': 31, 'person': 30, 'wife': 30, 'play': 30, 'foot': 30, 'bring': 30, 'murder': 29, 'movi': 29, 'precinct': 29, 'door': 29, 'stand': 29, 'plaqu': 29, 'forget': 28, 'woman': 28, 'girl': 28, 'hell': 28, 'rule': 28, 'bodi': 28, 'follow': 27, 'live': 27, 'hous': 27, 'today': 27, 'shut': 27, 'deal': 26, 'ladi': 26, 'hair': 26, 'write': 26, 'news': 26, 'heist': 26, 'spend': 25, 'figur': 25, 'wanna': 25, 'rest': 25, 'excus': 25, 'throw': 25, 'month': 25, 'stick': 25, 'suppos': 25, 'parti': 25, 'boss': 24, 'marri': 24, 'send': 24, 'burn': 24, 'kiss': 24, 'pictur': 23, 'hope': 23, 'mind': 23, 'mouth': 23, 'drive': 23, 'wed': 23, 'chang': 23, 'video': 22, 'sell': 22, 'wish': 22, 'hurt': 22, 'camera': 21, 'bust': 21, 'kind': 21, 'holt': 21, 'squad': 21, 'paperwork': 21, 'garbag': 21, 'miss': 21, 'letter': 21, 'matter': 21, 'money': 21, 'world': 21, 'prison': 21, 'rememb': 20, 'fact': 20, 'smile': 20, 'husband': 20, 'card': 20, 'reason': 20, 'lock': 20, 'store': 19, 'record': 19, 'prove': 19, 'evid': 19, 'sergeant': 19, 'hang': 19, 'slump': 19, 'choos': 19, 'bird': 19, 'heart': 19, 'second': 19, 'light': 19, 'handl': 19, 'joke': 18, 'agre': 18, 'morn': 18, 'book': 18, 'crap': 18, 'open': 18, 'secur': 18, 'costum': 18, 'step': 17, 'speak': 17, 'danc': 17, 'floor': 17, 'chair': 17, 'save': 17, 'worri': 17, 'bitch': 17, 'dinner': 17, 'school': 17, 'crown': 17, 'speech': 16, 'funer': 16, 'dream': 16, 'roll': 16, 'univers': 16, 'trash': 16, 'close': 16, 'bathroom': 16, 'forc': 16, 'scene': 15, 'depart': 15, 'laugh': 15, 'fault': 15, 'realiz': 15, 'lead': 15, 'coupl': 15, 'hide': 15, 'distract': 15, 'pigeon': 15, 'tooth': 15, 'marshal': 15, 'ball': 15, 'learn': 14, 'touch': 14, 'command': 14, 'window': 14, 'caus': 14, 'apart': 14, 'paint': 14, 'ruin': 14, 'street': 14, 'glass': 14, 'water': 14, 'understand': 14, 'punch': 14, 'present': 14, 'track': 14, 'fall': 14, 'shirt': 14, 'sarg': 14, 'food': 14, 'boom': 14, 'pass': 14, 'machin': 14, 'involv': 14, 'count': 14, 'tape': 14, 'cream': 14, 'earring': 14, 'dude': 13, 'photo': 13, 'stori': 13, 'draw': 13, 'manag': 13, 'cover': 13, 'screw': 13, 'sens': 13, 'suggest': 13, 'charg': 13, 'birthday': 13, 'blow': 13, 'assist': 13, 'tast': 13, 'death': 13, 'moment': 13, 'vultur': 13, 'suck': 13, 'paus': 13, 'type': 12, 'grow': 12, 'perp': 12, 'bunch': 12, 'offer': 12, 'piec': 12, 'cabinet': 12, 'chanc': 12, 'text': 12, 'dress': 12, 'damn': 12, 'beat': 12, 'jail': 12, 'mess': 12, 'weekend': 12, 'home': 12, 'credit': 12, 'weapon': 12, 'corkscrew': 12, 'sleep': 12, 'game': 12, 'promis': 12, 'vent': 12, 'trust': 12, 'apolog': 11, 'mark': 11, 'begin': 11, 'smell': 11, 'issu': 11, 'mistak': 11, 'dump': 11, 'fight': 11, 'answer': 11, 'carri': 11, 'imagin': 11, 'relationship': 11, 'share': 11, 'artist': 11, 'line': 11, 'replac': 11, 'cours': 11, 'decid': 11, 'address': 11, 'citi': 11, 'boyfriend': 11, 'prostitut': 11, 'park': 11, 'song': 11, 'balloon': 11, 'partner': 10, 'coffe': 10, 'copi': 10, 'wast': 10, 'grind': 10, 'cloth': 10, 'assum': 10, 'tase': 10, 'gift': 10, 'secret': 10, 'test': 10, 'shoulder': 10, 'brain': 10, 'idiot': 10, 'massag': 10, 'wall': 10, 'space': 10, 'right': 10, 'closet': 10, 'genius': 10, 'janitor': 10, 'drop': 10, 'admit': 10, 'blood': 10, 'seat': 10, 'threat': 10, 'chees': 10, 'chill': 10, 'pant': 10, 'truck': 10, 'attent': 9, 'dismiss': 9, 'paper': 9, 'search': 9, 'brother': 9, 'situat': 9, 'smoke': 9, 'brief': 9, 'crimin': 9, 'print': 9, 'career': 9, 'yogurt': 9, 'jerk': 9, 'quot': 9, 'swim': 9, 'risk': 9, 'troubl': 9, 'tomorrow': 9, 'defeat': 9, 'hunch': 9, 'ring': 9, 'slow': 9, 'good': 9, 'victim': 9, 'block': 9, 'trip': 9, 'email': 9, 'grab': 9, 'truth': 9, 'protect': 9, 'tickl': 9, 'task': 9, 'cigarett': 9, 'skate': 9, 'arch': 9, 'heater': 9, 'breath': 8, 'parent': 8, 'crack': 8, 'honor': 8, 'enjoy': 8, 'internet': 8, 'finish': 8, 'histori': 8, 'contact': 8, 'knock': 8, 'film': 8, 'minivan': 8, 'predict': 8, 'round': 8, 'wheel': 8, 'train': 8, 'killer': 8, 'wonder': 8, 'loser': 8, 'famili': 8, 'luck': 8, 'assign': 8, 'finger': 8, 'inspir': 8, 'tabl': 8, 'state': 8, 'strike': 8, 'rais': 8, 'primari': 8, 'purs': 8, 'cheer': 8, 'stress': 8, 'lawyer': 8, 'bottl': 8, 'kick': 8, 'expect': 8, 'favor': 8, 'attack': 8, 'sauc': 8, 'receiv': 8, 'bless': 8, 'messag': 8, 'power': 8, 'investig': 8, 'punk': 8, 'nightmar': 8, 'deserv': 8, 'galleri': 8, 'stare': 7, 'screen': 7, 'code': 7, 'bear': 7, 'moon': 7, 'robot': 7, 'interrupt': 7, 'voic': 7, 'welcom': 7, 'duti': 7, 'condit': 7, 'vehicl': 7, 'shoe': 7, 'program': 7, 'town': 7, 'father': 7, 'spray': 7, 'teach': 7, 'target': 7, 'page': 7, 'chocol': 7, 'race': 7, 'rock': 7, 'bone': 7, 'mission': 7, 'continu': 7, 'nail': 7, 'curs': 7, 'jump': 7, 'permiss': 7, 'stomach': 7, 'fridg': 7, 'knife': 7, 'mayor': 7, 'champion': 7, 'congratul': 7, 'anim': 7, 'swear': 7, 'medal': 7, 'hero': 7, 'surpris': 7, 'suit': 7, 'advic': 7, 'accent': 7, 'announc': 7, 'trap': 7, 'wake': 7, 'blink': 7, 'guard': 7, 'alibi': 7, 'explain': 7, 'tongu': 7, 'busi': 7, 'hire': 7, 'yell': 7, 'girlfriend': 7, 'fish': 7, 'group': 7, 'fenc': 7, 'pipe': 7, 'employe': 6, 'inform': 6, 'insid': 6, 'updat': 6, 'alert': 6, 'cheek': 6, 'muffin': 6, 'notic': 6, 'option': 6, 'suspend': 6, 'feloni': 6, 'vandal': 6, 'peni': 6, 'gentleman': 6, 'respect': 6, 'backup': 6, 'account': 6, 'sheriff': 6, 'divorc': 6, 'ceil': 6, 'hamper': 6, 'basket': 6, 'collar': 6, 'wrap': 6, 'choic': 6, 'discuss': 6, 'yesterday': 6, 'doctor': 6, 'match': 6, 'communiti': 6, 'child': 6, 'music': 6, 'accept': 6, 'bench': 6, 'connect': 6, 'allow': 6, 'bother': 6, 'pressur': 6, 'bank': 6, 'mood': 6, 'tree': 6, 'breakfast': 6, 'clock': 6, 'includ': 6, 'note': 6, 'celebr': 6, 'sneak': 6, 'brag': 6, 'candi': 6, 'jurisdict': 6, 'insist': 6, 'cell': 6, 'slash': 6, 'trick': 6, 'class': 6, 'sort': 6, 'midnight': 6, 'graduat': 6, 'daughter': 6, 'subway': 6, 'pretend': 6, 'failur': 6, 'diaper': 6, 'relat': 6, 'accord': 6, 'post': 6, 'plane': 6, 'form': 6, 'cage': 6, 'bullet': 6, 'crash': 6, 'fireman': 6, 'engag': 6, 'engin': 6, 'spoon': 6, 'fool': 6, 'poster': 6, 'campaign': 6, 'dope': 6, 'attempt': 6, 'interrog': 6, 'oath': 6, 'backpack': 6, 'laptop': 5, 'access': 5, 'ticket': 5, 'nicknam': 5, 'wallet': 5, 'incid': 5, 'return': 5, 'fine': 5, 'ride': 5, 'remind': 5, 'confess': 5, 'dealer': 5, 'wiener': 5, 'colleg': 5, 'color': 5, 'sing': 5, 'refus': 5, 'sigh': 5, 'buck': 5, 'adult': 5, 'cocain': 5, 'grade': 5, 'statu': 5, 'bubbl': 5, 'trevor': 5, 'threaten': 5, 'assault': 5, 'robberi': 5, 'remain': 5, 'speed': 5, 'bump': 5, 'road': 5, 'pile': 5, 'volunt': 5, 'frisk': 5, 'build': 5, 'rabbit': 5, 'scream': 5, 'approv': 5, 'muscl': 5, 'switch': 5, 'salmon': 5, 'wit': 5, 'shower': 5, 'borrow': 5, 'control': 5, 'lover': 5, 'weigh': 5, 'struggl': 5, 'medicin': 5, 'insult': 5, 'cruis': 5, 'treat': 5, 'hors': 5, 'affair': 5, 'wind': 5, 'stink': 5, 'milk': 5, 'court': 5, 'reveng': 5, 'motorcycl': 5, 'badg': 5, 'prepar': 5, 'fart': 5, 'stab': 5, 'press': 5, 'crush': 5, 'invit': 5, 'calm': 5, 'overtim': 5, 'schedul': 5, 'airplan': 5, 'corner': 5, 'warehous': 5, 'jacket': 5, 'mother': 5, 'model': 5, 'transfer': 5, 'handcuff': 5, 'ident': 5, 'moron': 5, 'legit': 5, 'rise': 5, 'pleasur': 5, 'brush': 5, 'psycho': 5, 'middl': 5, 'holiday': 5, 'accid': 5, 'bore': 5, 'clear': 5, 'teacher': 5, 'jewelri': 5, 'cancel': 5, 'pawn': 5, 'restaur': 5, 'colleagu': 5, 'disast': 5, 'bucket': 5, 'blast': 5, 'snap': 5, 'rate': 5, 'quit': 5, 'clean': 5, 'grackl': 5, 'delet': 5, 'plate': 5, 'soda': 5, 'floozi': 5, 'urin': 5, 'toast': 5, 'tattoo': 5, 'witch': 5, 'monster': 5, 'roof': 5, 'boost': 5, 'robber': 5, 'piggi': 5, 'caboodl': 5, 'sober': 5, 'dino': 5, 'flip': 4, 'appear': 4, 'gunk': 4, 'focus': 4, 'introduc': 4, 'phrase': 4, 'roller': 4, 'rabbi': 4, 'wash': 4, 'imit': 4, 'vibe': 4, 'cure': 4, 'neighbor': 4, 'practic': 4, 'guarante': 4, 'locker': 4, 'warrant': 4, 'spot': 4, 'babysitt': 4, 'studi': 4, 'vision': 4, 'experi': 4, 'sandal': 4, 'chase': 4, 'combin': 4, 'mention': 4, 'decis': 4, 'research': 4, 'process': 4, 'properti': 4, 'destini': 4, 'daddi': 4, 'bail': 4, 'click': 4, 'suspect': 4, 'base': 4, 'grandma': 4, 'darl': 4, 'recogn': 4, 'pocket': 4, 'meth': 4, 'poop': 4, 'field': 4, 'destroy': 4, 'insur': 4, 'talent': 4, 'advers': 4, 'station': 4, 'custom': 4, 'doodl': 4, 'memori': 4, 'earth': 4, 'chest': 4, 'unit': 4, 'respons': 4, 'regret': 4, 'vend': 4, 'explod': 4, 'size': 4, 'elev': 4, 'stat': 4, 'releas': 4, 'strategi': 4, 'center': 4, 'request': 4, 'rang': 4, 'join': 4, 'neighborhood': 4, 'hallway': 4, 'spider': 4, 'hole': 4, 'level': 4, 'throat': 4, 'dryer': 4, 'winner': 4, 'freak': 4, 'role': 4, 'drawer': 4, 'chute': 4, 'land': 4, 'consid': 4, 'disobey': 4, 'fear': 4, 'season': 4, 'jake': 4, 'fail': 4, 'divers': 4, 'draft': 4, 'appli': 4, 'hook': 4, 'pfft': 4, 'purpos': 4, 'shame': 4, 'bribe': 4, 'hurri': 4, 'pineappl': 4, 'idol': 4, 'articl': 4, 'spirit': 4, 'pattern': 4, 'initi': 4, 'psych': 4, 'sandwich': 4, 'hack': 4, 'energi': 4, 'alarm': 4, 'protocol': 4, 'safeti': 4, 'flight': 4, 'stamp': 4, 'peac': 4, 'decor': 4, 'honey': 4, 'phase': 4, 'associ': 4, 'qualiti': 4, 'metal': 4, 'hunt': 4, 'tune': 4, 'cowork': 4, 'nois': 4, 'fingerprint': 4, 'shop': 4, 'club': 4, 'crust': 4, 'recip': 4, 'download': 4, 'doughnut': 4, 'savant': 4, 'doubt': 4, 'serv': 4, 'plenti': 4, 'buyer': 4, 'surveil': 4, 'effici': 4, 'surviv': 4, 'wuntch': 4, 'mascot': 4, 'shampoo': 4, 'slip': 4, 'fake': 4, 'workplac': 4, 'demot': 4, 'childhood': 4, 'sake': 4, 'vegan': 4, 'mango': 4, 'marriag': 4, 'cash': 4, 'slayer': 4, 'liar': 4, 'briefcas': 4, 'tick': 4, 'breast': 4, 'charact': 4, 'promot': 4, 'remov': 4, 'pair': 4, 'sweat': 4, 'cane': 4, 'soup': 4, 'binder': 4, 'weirdo': 3, 'list': 3, 'tech': 3, 'zone': 3, 'pencil': 3, 'puzzl': 3, 'environ': 3, 'pain': 3, 'coron': 3, 'label': 3, 'undi': 3, 'plant': 3, 'babysit': 3, 'overhear': 3, 'degre': 3, 'scienc': 3, 'design': 3, 'locat': 3, 'mixtap': 3, 'perfect': 3, 'freez': 3, 'wolf': 3, 'bedroom': 3, 'piss': 3, 'lunch': 3, 'theft': 3, 'tone': 3, 'chemistri': 3, 'friendship': 3, 'gather': 3, 'burglari': 3, 'aggrav': 3, 'lack': 3, 'grandson': 3, 'craft': 3, 'stack': 3, 'seminar': 3, 'student': 3, 'info': 3, 'greet': 3, 'stranger': 3, 'swap': 3, 'mule': 3, 'prank': 3, 'comin': 3, 'unload': 3, 'contain': 3, 'enter': 3, 'coma': 3, 'castl': 3, 'leather': 3, 'passion': 3, 'exist': 3, 'fraud': 3, 'justic': 3, 'selfi': 3, 'deni': 3, 'datum': 3, 'term': 3, 'candid': 3, 'poison': 3, 'grader': 3, 'wing': 3, 'betray': 3, 'result': 3, 'attract': 3, 'lung': 3, 'mode': 3, 'half': 3, 'homicid': 3, 'skill': 3, 'lean': 3, 'frame': 3, 'spell': 3, 'improv': 3, 'doorman': 3, 'toilet': 3, 'stanc': 3, 'nose': 3, 'overthink': 3, 'relax': 3, 'butthead': 3, 'disrupt': 3, 'alcohol': 3, 'overstep': 3, 'troup': 3, 'scratch': 3, 'challeng': 3, 'particip': 3, 'haircut': 3, 'lower': 3, 'church': 3, 'chess': 3, 'king': 3, 'creat': 3, 'blend': 3, 'exit': 3, 'groan': 3, 'flush': 3, 'trade': 3, 'sister': 3, 'favorit': 3, 'climb': 3, 'escap': 3, 'teamwork': 3, 'titl': 3, 'convinc': 3, 'papa': 3, 'boot': 3, 'lnternet': 3, 'satisfact': 3, 'thug': 3, 'crowbar': 3, 'scotch': 3, 'chicken': 3, 'lesson': 3, 'hangov': 3, 'star': 3, 'pool': 3, 'ignor': 3, 'fountain': 3, 'error': 3, 'client': 3, 'defend': 3, 'manipul': 3, 'determin': 3, 'item': 3, 'sight': 3, 'coat': 3, 'repeat': 3, 'angel': 3, 'horrifi': 3, 'cuff': 3, 'skin': 3, 'mask': 3, 'mail': 3, 'coordin': 3, 'storm': 3, 'avoid': 3, 'emerg': 3, 'pepper': 3, 'pickl': 3, 'attitud': 3, 'saltwat': 3, 'taffi': 3, 'footag': 3, 'wire': 3, 'servic': 3, 'bell': 3, 'fudg': 3, 'calori': 3, 'institut': 3, 'arson': 3, 'rank': 3, 'competit': 3, 'slice': 3, 'board': 3, 'cyber': 3, 'weak': 3, 'adopt': 3, 'abandon': 3, 'owner': 3, 'interview': 3, 'thief': 3, 'trail': 3, 'real': 3, 'progress': 3, 'toddler': 3, 'startl': 3, 'health': 3, 'propos': 3, 'march': 3, 'realiti': 3, 'crane': 3, 'necklac': 3, 'crew': 3, 'go': 3, 'upset': 3, 'warm': 3, 'guest': 3, 'habit': 3, 'counsel': 3, 'donut': 3, 'octopus': 3, 'stain': 3, 'accus': 3, 'support': 3, 'theori': 3, 'brand': 3, 'whatnot': 3, 'storag': 3, 'babe': 3, 'intend': 3, 'setup': 3, 'victori': 3, 'misdemeanor': 3, 'direct': 3, 'snack': 3, 'port': 3, 'dare': 3, 'ginkgo': 3, 'oeuvr': 3, 'whoa': 3, 'tortur': 3, 'sink': 3, 'battl': 3, 'object': 3, 'blind': 3, 'oper': 3, 'whore': 3, 'tock': 3, 'blame': 3, 'quiz': 3, 'otch': 3, 'posit': 3, 'extermin': 3, 'snake': 3, 'cross': 3, 'maim': 3, 'lure': 3, 'exam': 3, 'abil': 3, 'duck': 3, 'mistress': 3, 'bounc': 3, 'moral': 3, 'allergi': 3, 'embarrass': 3, 'advis': 3, 'teammat': 3, 'dentist': 3, 'reset': 3, 'sitter': 3, 'union': 3, 'pigtail': 3, 'bellini': 3, 'batter': 3, 'tank': 3, 'undermin': 3, 'overmin': 3, 'launder': 3, 'male': 2, 'flan': 2, 'pud': 2, 'concert': 2, 'mentor': 2, 'pusher': 2, 'meep': 2, 'session': 2, 'valu': 2, 'uncl': 2, 'administr': 2, 'action': 2, 'caress': 2, 'weed': 2, 'bolt': 2, 'mous': 2, 'bait': 2, 'palm': 2, 'footwear': 2, 'behavior': 2, 'futur': 2, 'disguis': 2, 'micromanag': 2, 'nypd': 2, 'breaker': 2, 'highland': 2, 'kindergarten': 2, 'area': 2, 'kilo': 2, 'bean': 2, 'injur': 2, 'offens': 2, 'brutal': 2, 'categori': 2, 'occas': 2, 'orient': 2, 'thousand': 2, 'dollar': 2, 'slide': 2, 'complaint': 2, 'scare': 2, 'lookin': 2, 'refrain': 2, 'fee': 2, 'sweater': 2, 'digit': 2, 'absenc': 2, 'conclus': 2, 'prize': 2, 'mound': 2, 'stock': 2, 'bagel': 2, 'proceed': 2, 'prais': 2, 'lineup': 2, 'snitch': 2, 'kid': 2, 'generat': 2, 'instinct': 2, 'path': 2, 'presid': 2, 'dollhous': 2, 'affix': 2, 'dunker': 2, 'grandmoth': 2, 'liver': 2, 'kidney': 2, 'drip': 2, 'accomplic': 2, 'examin': 2, 'carpet': 2, 'respond': 2, 'riot': 2, 'decad': 2, 'lift': 2, 'cramp': 2, 'clubhous': 2, 'entri': 2, 'homi': 2, 'appreci': 2, 'siren': 2, 'flick': 2, 'blare': 2, 'fantasi': 2, 'statist': 2, 'snatcher': 2, 'sketch': 2, 'pound': 2, 'belt': 2, 'chipper': 2, 'neck': 2, 'content': 2, 'loss': 2, 'mourn': 2, 'organ': 2, 'assess': 2, 'trauma': 2, 'bruis': 2, 'retir': 2, 'button': 2, 'beaut': 2, 'earn': 2, 'dictat': 2, 'gold': 2, 'leadership': 2, 'clich': 2, 'silenc': 2, 'yard': 2, 'footbal': 2, 'refer': 2, 'corps': 2, 'motiv': 2, 'opportun': 2, 'heat': 2, 'resourc': 2, 'thunder': 2, 'pointer': 2, 'cool': 2, 'champ': 2, 'effort': 2, 'tire': 2, 'hospit': 2, 'recertifi': 2, 'tissu': 2, 'cedar': 2, 'default': 2, 'chug': 2, 'besti': 2, 'split': 2, 'mastermind': 2, 'valor': 2, 'softi': 2, 'hint': 2, 'lotion': 2, 'vomit': 2, 'vodka': 2, 'boob': 2, 'deliveri': 2, 'handwrit': 2, 'bunni': 2, 'crispi': 2, 'push': 2, 'concentr': 2, 'master': 2, 'ditch': 2, 'bread': 2, 'gotcha': 2, 'astronaut': 2, 'clown': 2, 'mall': 2, 'chain': 2, 'ballet': 2, 'dancer': 2, 'chuckl': 2, 'blowtorch': 2, 'shake': 2, 'strength': 2, 'perform': 2, 'commenc': 2, 'dust': 2, 'reveal': 2, 'passcod': 2, 'assumpt': 2, 'flirt': 2, 'drag': 2, 'stretch': 2, 'timer': 2, 'appeal': 2, 'success': 2, 'stume': 2, 'runner': 2, 'outta': 2, 'turkey': 2, 'virgin': 2, 'choke': 2, 'ponytail': 2, 'testifi': 2, 'dumbass': 2, 'comb': 2, 'transact': 2, 'mafia': 2, 'reduc': 2, 'buddi': 2, 'indict': 2, 'flinch': 2, 'pong': 2, 'salad': 2, 'bond': 2, 'develop': 2, 'pack': 2, 'declar': 2, 'differ': 2, 'protein': 2, 'beef': 2, 'purchas': 2, 'coach': 2, 'regard': 2, 'slam': 2, 'human': 2, 'fuse': 2, 'linguini': 2, 'brown': 2, 'centuri': 2, 'advantag': 2, 'stickler': 2, 'defens': 2, 'diabet': 2, 'booz': 2, 'burrito': 2, 'testicl': 2, 'repres': 2, 'hoax': 2, 'author': 2, 'airport': 2, 'singl': 2, 'codenam': 2, 'restroom': 2, 'fixat': 2, 'couch': 2, 'pillow': 2, 'escort': 2, 'limit': 2, 'yike': 2, 'fold': 2, 'gear': 2, 'reach': 2, 'rubber': 2, 'disappoint': 2, 'twitch': 2, 'drown': 2, 'stapl': 2, 'meter': 2, 'cement': 2, 'lockup': 2, 'bastard': 2, 'trace': 2, 'radio': 2, 'trigger': 2, 'ambul': 2, 'diamond': 2, 'makeup': 2, 'lawsuit': 2, 'doubl': 2, 'bulli': 2, 'websit': 2, 'shine': 2, 'possess': 2, 'goate': 2, 'yawn': 2, 'surgeri': 2, 'debit': 2, 'statement': 2, 'toothbrush': 2, 'secretari': 2, 'patch': 2, 'bike': 2, 'loot': 2, 'dessert': 2, 'virus': 2, 'grunt': 2, 'tragedi': 2, 'clerk': 2, 'gasolin': 2, 'leader': 2, 'tear': 2, 'cone': 2, 'palat': 2, 'condol': 2, 'gino': 2, 'encrypt': 2, 'pimpin': 2, 'collect': 2, 'ster': 2, 'escal': 2, 'obsess': 2, 'bungl': 2, 'deputi': 2, 'reaction': 2, 'thumb': 2, 'govern': 2, 'tail': 2, 'agreement': 2, 'succubus': 2, 'archiv': 2, 'reserv': 2, 'spring': 2, 'honeymoon': 2, 'motto': 2, 'stutter': 2, 'humor': 2, 'refil': 2, 'farm': 2, 'style': 2, 'french': 2, 'keep': 2, 'spill': 2, 'feud': 2, 'spread': 2, 'ghost': 2, 'sucker': 2, 'brake': 2, 'doom': 2, 'deliv': 2, 'boobi': 2, 'vest': 2, 'beer': 2, 'douch': 2, 'bullpen': 2, 'visit': 2, 'sniff': 2, 'bouquet': 2, 'bagpip': 2, 'convers': 2, 'chat': 2, 'stupidfac': 2, 'bracelet': 2, 'wrist': 2, 'counter': 2, 'exampl': 2, 'exchang': 2, 'intercours': 2, 'junk': 2, 'clap': 2, 'incom': 2, 'takoyaki': 2, 'imag': 2, 'band': 2, 'pardon': 2, 'showcas': 2, 'pose': 2, 'widow': 2, 'compani': 2, 'driver': 2, 'judgment': 2, 'slogan': 2, 'debt': 2, 'barista': 2, 'outfit': 2, 'societi': 2, 'canva': 2, 'intoler': 2, 'overreact': 2, 'horn': 2, 'receipt': 2, 'onlin': 2, 'abus': 2, 'critic': 2, 'consequ': 2, 'sugar': 2, 'smuggl': 2, 'spook': 2, 'stencil': 2, 'cacao': 2, 'rainforest': 2, 'punish': 2, 'warpath': 2, 'skraight': 2, 'oolong': 2, 'angl': 2, 'comment': 2, 'signatur': 2, 'dork': 2, 'shelf': 2, 'factori': 2, 'metaphor': 2, 'drivel': 2, 'turd': 2, 'reinstat': 2, 'goal': 2, 'fungus': 2, 'roach': 2, 'cleavag': 2, 'twist': 2, 'chip': 2, 'retriev': 2, 'hail': 2, 'noic': 2, 'opposit': 2, 'raid': 2, 'endang': 2, 'sale': 2, 'dumb': 2, 'heel': 2, 'resum': 2, 'derek': 2, 'pornographi': 2, 'kart': 2, 'calf': 2, 'princip': 2, 'porn': 2, 'upload': 2, 'dragon': 2, 'corn': 2, 'demand': 2, 'player': 2, 'waltz': 2, 'handgun': 2, 'licens': 2, 'wink': 2, 'ammo': 2, 'adio': 2, 'chao': 2, 'grenad': 2, 'treadmil': 2, 'enforc': 2, 'swampsgiv': 2, 'jailbreak': 2, 'basebal': 2, 'fugit': 2, 'hostag': 2, 'suppli': 2, 'flash': 2, 'ambi': 2, 'stitch': 2, 'booster': 2, 'twin': 2, 'impact': 2, 'airbag': 2, 'ambush': 2, 'pump': 2, 'forehead': 2, 'dish': 2, 'squat': 2, 'rewind': 2, 'clutch': 2, 'whisper': 2, 'fianc': 2, 'lick': 2, 'sync': 2, 'shout': 2, 'sassi': 2, 'arriv': 2, 'rigiti': 2, 'smash': 2, 'bing': 2, 'exposur': 2, 'crossov': 2, 'capit': 2, 'correct': 2, 'prefer': 2, 'dale': 2, 'whoop': 2, 'stash': 2, 'cabbag': 2, 'prop': 2, 'panic': 2, 'pilot': 2, 'warn': 2, 'increment': 2, 'menu': 2, 'juic': 2, 'champagn': 2, 'merchandis': 2, 'rainstick': 2, 'belong': 2, 'quieter': 2, 'trelli': 2, 'lane': 2, 'winker': 2, 'rhyme': 2, 'supplier': 2, 'territori': 2, 'express': 2, 'fumfer': 2, 'usag': 2, 'lamin': 2, 'lieuten': 2, 'flame': 2, 'snaccid': 2, 'tablet': 1, 'nanni': 1, 'devic': 1, 'electron': 1, 'plug': 1, 'broadcast': 1, 'butterscotch': 1, 'prioriti': 1, 'scalper': 1, 'flare': 1, 'emphas': 1, 'swing': 1, 'extinguish': 1, 'patrol': 1, 'guid': 1, 'zeep': 1, 'recap': 1, 'impli': 1, 'zarp': 1, 'neckti': 1, 'suav': 1, 'titti': 1, 'chubbi': 1, 'edg': 1, 'jumpi': 1, 'scarf': 1, 'grinder': 1, 'mandat': 1, 'therapi': 1, 'gorg': 1, 'constip': 1, 'festiv': 1, 'forum': 1, 'silk': 1, 'robe': 1, 'bong': 1, 'plumb': 1, 'mislabel': 1, 'folder': 1, 'confus': 1, 'kudo': 1, 'decoy': 1, 'tarot': 1, 'numerolog': 1, 'encount': 1, 'blue': 1, 'stakeout': 1, 'cassett': 1, 'taser': 1, 'cantaloup': 1, 'hungov': 1, 'hamburg': 1, 'fellow': 1, 'granni': 1, 'belief': 1, 'ensembl': 1, 'pursu': 1, 'defin': 1, 'tagger': 1, 'procur': 1, 'restor': 1, 'status': 1, 'glitter': 1, 'academi': 1, 'repaint': 1, 'humid': 1, 'cycl': 1, 'minor': 1, 'bearer': 1, 'depress': 1, 'defac': 1, 'diagram': 1, 'section': 1, 'burden': 1, 'bridg': 1, 'blond': 1, 'scenario': 1, 'whiteboard': 1, 'smack': 1, 'whim': 1, 'cosmo': 1, 'bummer': 1, 'offici': 1, 'possibl': 1, 'scholarship': 1, 'worth': 1, 'damag': 1, 'font': 1, 'salesman': 1, 'dozen': 1, 'destruct': 1, 'enemi': 1, 'hawk': 1, 'uniform': 1, 'violenc': 1, 'leon': 1, 'hooker': 1, 'slayin': 1, 'corduroy': 1, 'thingi': 1, 'canyon': 1, 'stall': 1, 'analog': 1, 'racecar': 1, 'formula': 1, 'descript': 1, 'storytel': 1, 'reunit': 1, 'croissant': 1, 'bang': 1, 'outreach': 1, 'dive': 1, 'farmer': 1, 'market': 1, 'pretti': 1, 'packet': 1, 'trumpet': 1, 'fanfar': 1, 'hotel': 1, 'brainer': 1, 'doll': 1, 'tower': 1, 'turret': 1, 'sentenc': 1, 'mojo': 1, 'offend': 1, 'identifi': 1, 'earbud': 1, 'badass': 1, 'minuet': 1, 'flute': 1, 'hall': 1, 'gland': 1, 'mishandl': 1, 'towel': 1, 'freakiest': 1, 'volleybal': 1, 'casework': 1, 'shallow': 1, 'hitchcock': 1, 'tupperwar': 1, 'cute': 1, 'correspond': 1, 'forefing': 1, 'pinki': 1, 'fairi': 1, 'princess': 1, 'clatter': 1, 'dresser': 1, 'trucker': 1, 'denim': 1, 'obstruct': 1, 'recruit': 1, 'repay': 1, 'percent': 1, 'reboot': 1, 'takeback': 1, 'snag': 1, 'spiral': 1, 'assembl': 1, 'flourish': 1, 'dainti': 1, 'nightingal': 1, 'strangler': 1, 'lettuc': 1, 'triumph': 1, 'threesom': 1, 'skip': 1, 'eyewit': 1, 'barbado': 1, 'weav': 1, 'frond': 1, 'stingray': 1, 'funniest': 1, 'spoiler': 1, 'starvat': 1, 'defibril': 1, 'kitchen': 1, 'compliment': 1, 'album': 1, 'devast': 1, 'heartach': 1, 'bulldoz': 1, 'catalogu': 1, 'motionless': 1, 'industri': 1, 'motion': 1, 'reactiv': 1, 'autopsi': 1, 'inflam': 1, 'probe': 1, 'ocean': 1, 'bloat': 1, 'odor': 1, 'futon': 1, 'afternoon': 1, 'caviti': 1, 'alien': 1, 'boardwalk': 1, 'caricatur': 1, 'surfboard': 1, 'noon': 1, 'intestin': 1, 'steed': 1, 'armor': 1, 'scar': 1, 'ingest': 1, 'terrifi': 1, 'concern': 1, 'backfir': 1, 'feather': 1, 'grant': 1, 'brushwork': 1, 'torqu': 1, 'transform': 1, 'lineback': 1, 'loop': 1, 'citizen': 1, 'personnel': 1, 'ensu': 1, 'accompani': 1, 'piata': 1, 'marksman': 1, 'blam': 1, 'certifi': 1, 'novel': 1, 'bite': 1, 'tiger': 1, 'shush': 1, 'swoop': 1, 'context': 1, 'protest': 1, 'extort': 1, 'powder': 1, 'macchiato': 1, 'cancer': 1, 'itch': 1, 'weaver': 1, 'isoscel': 1, 'shackl': 1, 'melt': 1, 'alo': 1, 'popcorn': 1, 'microwav': 1, 'potato': 1, 'drugstor': 1, 'travel': 1, 'waitress': 1, 'argu': 1, 'walker': 1, 'silhouett': 1, 'wingman': 1, 'airtight': 1, 'spark': 1, 'philander': 1, 'toss': 1, 'sweetheart': 1, 'magnet': 1, 'flashlight': 1, 'panel': 1, 'caw': 1, 'influenc': 1, 'overcom': 1, 'suction': 1, 'separ': 1, 'undercov': 1, 'nerd': 1, 'getaway': 1, 'peel': 1, 'bandit': 1, 'short': 1, 'interfer': 1, 'poem': 1, 'activ': 1, 'skeleton': 1, 'partier': 1, 'safe': 1, 'butter': 1, 'shell': 1, 'whoo': 1, 'shoulda': 1, 'concuss': 1, 'deciph': 1, 'werewolf': 1, 'cowboy': 1, 'mustard': 1, 'grope': 1, 'gambit': 1, 'sacrific': 1, 'bewar': 1, 'loosen': 1, 'tournament': 1, 'lupus': 1, 'forg': 1, 'crucibl': 1, 'volit': 1, 'scale': 1, 'endgam': 1, 'core': 1, 'underestim': 1, 'estim': 1, 'deadlin': 1, 'flashback': 1, 'mistim': 1, 'herring': 1, 'member': 1, 'key': 1, 'smudg': 1, 'explan': 1, 'charl': 1, 'underestima': 1, 'spare': 1, 'checkmat': 1, 'camraderi': 1, 'rous': 1, 'ridicul': 1, 'provid': 1, 'mugger': 1, 'ballerina': 1, 'stench': 1, 'bomb': 1, 'wipe': 1, 'mobster': 1, 'hippi': 1, 'observ': 1, 'presenc': 1, 'evil': 1, 'courtroom': 1, 'demeanor': 1, 'simpl': 1, 'stenograph': 1, 'scanner': 1, 'ashtray': 1, 'cope': 1, 'mumbo': 1, 'jumbo': 1, 'slob': 1, 'skull': 1, 'kneecap': 1, 'data': 1, 'juri': 1, 'moustach': 1, 'corrupt': 1, 'sexism': 1, 'matchstick': 1, 'rican': 1, 'dawn': 1, 'bartend': 1, 'ping': 1, 'platform': 1, 'wardrob': 1, 'villain': 1, 'soften': 1, 'donat': 1, 'bankruptci': 1, 'grandpa': 1, 'yolk': 1, 'river': 1, 'embryo': 1, 'loaf': 1, 'algorithm': 1, 'aspirin': 1, 'tide': 1, 'counselor': 1, 'grundhaven': 1, 'candor': 1, 'cave': 1, 'verticuli': 1, 'dummi': 1, 'slurp': 1, 'noodl': 1, 'pesto': 1, 'starv': 1, 'crawl': 1, 'instig': 1, 'panti': 1, 'pretzel': 1, 'underwear': 1, 'swampi': 1, 'everglad': 1, 'homo': 1, 'cabin': 1, 'attorney': 1, 'eval': 1, 'embodi': 1, 'cower': 1, 'beep': 1, 'claus': 1, 'brawl': 1, 'cont': 1, 'chariti': 1, 'canin': 1, 'reek': 1, 'mel': 1, 'beard': 1, 'cherri': 1, 'soulmat': 1, 'wisdom': 1, 'urg': 1, 'circumst': 1, 'entail': 1, 'movement': 1, 'evalu': 1, 'psychologist': 1, 'psychic': 1, 'indic': 1, 'peer': 1, 'readi': 1, 'hover': 1, 'motel': 1, 'evad': 1, 'dothat': 1, 'falcon': 1, 'goof': 1, 'lockdown': 1, 'privaci': 1, 'amigo': 1, 'creepi': 1, 'sprain': 1, 'lord': 1, 'flag': 1, 'liquor': 1, 'grass': 1, 'uncuff': 1, 'lyiiiiinngggg': 1, 'din': 1, 'black': 1, 'transcript': 1, 'rout': 1, 'classic': 1, 'relay': 1, 'frown': 1, 'acn': 1, 'brash': 1, 'sandalwood': 1, 'intel': 1, 'project': 1, 'hazelnut': 1, 'rail': 1, 'goodi': 1, 'channel': 1, 'lust': 1, 'stake': 1, 'converg': 1, 'emot': 1, 'myyyyyyi': 1, 'shrink': 1, 'danger': 1, 'grit': 1, 'sorri': 1, 'nooooo': 1, 'tain': 1, 'armi': 1, 'bypass': 1, 'carat': 1, 'bray': 1, 'catcal': 1, 'rash': 1, 'jeopard': 1, 'demonstr': 1, 'debacl': 1, 'chin': 1, 'blogg': 1, 'foodi': 1, 'stew': 1, 'trial': 1, 'froofi': 1, 'frappuccino': 1, 'squeez': 1, 'workout': 1, 'sith': 1, 'nightgown': 1, 'seced': 1, 'overton': 1, 'sanit': 1, 'annoy': 1, 'strum': 1, 'guitar': 1, 'shriek': 1, 'brunt': 1, 'reschedul': 1, 'garin': 1, 'jaunti': 1, 'sunset': 1, 'devil': 1, 'punctuat': 1, 'dreamboat': 1, 'blammo': 1, 'basketbal': 1, 'partial': 1, 'stifl': 1, 'laser': 1, 'recuper': 1, 'compon': 1, 'meringu': 1, 'weakl': 1, 'pocono': 1, 'nightclub': 1, 'blowup': 1, 'thrive': 1, 'dysfunct': 1, 'knit': 1, 'standard': 1, 'soul': 1, 'tingl': 1, 'isl': 1, 'condom': 1, 'expir': 1, 'conceal': 1, 'baguett': 1, 'mate': 1, 'whistl': 1, 'canal': 1, 'server': 1, 'discoveri': 1, 'nimrod': 1, 'dishwar': 1, 'tread': 1, 'geni': 1, 'estat': 1, 'rosa': 1, 'textur': 1, 'thigh': 1, 'conduct': 1, 'doofus': 1, 'island': 1, 'mope': 1, 'rebuild': 1, 'torch': 1, 'pizzeria': 1, 'radius': 1, 'ladder': 1, 'holster': 1, 'consist': 1, 'ratio': 1, 'travesti': 1, 'spit': 1, 'amateur': 1, 'poof': 1, 'integr': 1, 'parole': 1, 'queri': 1, 'softwar': 1, 'analysi': 1, 'muffl': 1, 'skootch': 1, 'gingiv': 1, 'garden': 1, 'calico': 1, 'marshmallow': 1, 'measur': 1, 'leagu': 1, 'firefight': 1, 'reconsid': 1, 'printer': 1, 'floss': 1, 'paycheck': 1, 'therapist': 1, 'jimmi': 1, 'pole': 1, 'char': 1, 'flavorless': 1, 'maron': 1, 'quaint': 1, 'whack': 1, 'tricycl': 1, 'bakeri': 1, 'attach': 1, 'harm': 1, 'boon': 1, 'shave': 1, 'retali': 1, 'laughter': 1, 'carrot': 1, 'salut': 1, 'digniti': 1, 'diggiti': 1, 'crumb': 1, 'undercut': 1, 'awkward': 1, 'profession': 1, 'commission': 1, 'simper': 1, 'buffoon': 1, 'snoop': 1, 'insatiab': 1, 'sidepiec': 1, 'augustin': 1, 'handoff': 1, 'marrow': 1, 'custard': 1, 'genderless': 1, 'blob': 1, 'sport': 1, 'forearm': 1, 'host': 1, 'goos': 1, 'sourc': 1, 'lawn': 1, 'novic': 1, 'watcher': 1, 'establish': 1, 'numbnut': 1, 'superior': 1, 'mrmmzeep': 1, 'jinglebin': 1, 'stone': 1, 'reassign': 1, 'valv': 1, 'gene': 1, 'perspect': 1, 'equip': 1, 'countdown': 1, 'complet': 1, 'monitor': 1, 'backgammon': 1, 'ambianc': 1, 'weight': 1, 'fit': 1, 'flooz': 1, 'reli': 1, 'arigato': 1, 'kamikaz': 1, 'deet': 1, 'glow': 1, 'root': 1, 'seductress': 1, 'chore': 1, 'crunch': 1, 'immacul': 1, 'breather': 1, 'agenda': 1, 'trent': 1, 'narrow': 1, 'nonthreaten': 1, 'carrier': 1, 'diseas': 1, 'outlaw': 1, 'make': 1, 'wrapper': 1, 'snork': 1, 'maintain': 1, 'bullfight': 1, 'shoebox': 1, 'buri': 1, 'hamster': 1, 'truce': 1, 'name': 1, 'timberlak': 1, 'faton': 1, 'alter': 1, 'ship': 1, 'breezi': 1, 'linen': 1, 'pantsuit': 1, 'rain': 1, 'soak': 1, 'launch': 1, 'fragranc': 1, 'rumor': 1, 'ding': 1, 'dong': 1, 'past': 1, 'recept': 1, 'bulletproof': 1, 'peach': 1, 'housekeep': 1, 'befriend': 1, 'puk': 1, 'dial': 1, 'downfal': 1, 'plot': 1, 'bleh': 1, 'applaud': 1, 'sway': 1, 'desist': 1, 'impress': 1, 'showman': 1, 'drama': 1, 'wild': 1, 'boneyard': 1, 'kettlebel': 1, 'harass': 1, 'guidelin': 1, 'jockey': 1, 'banter': 1, 'zinger': 1, 'cranki': 1, 'griev': 1, 'elbow': 1, 'overrul': 1, 'tragic': 1, 'render': 1, 'simpleton': 1, 'tweak': 1, 'toler': 1, 'dillwe': 1, 'catfight': 1, 'arrang': 1, 'eat': 1, 'discontinu': 1, 'backwood': 1, 'orgi': 1, 'banana': 1, 'pray': 1, 'chunki': 1, 'confid': 1, 'obstacl': 1, 'nether': 1, 'syntax': 1, 'vocabulari': 1, 'public': 1, 'medium': 1, 'fianc': 1, 'carniv': 1, 'sunglass': 1, 'tarantula': 1, 'dermot': 1, 'crawler': 1, 'sorrow': 1, 'catfish': 1, 'chef': 1, 'cwim': 1, 'rat': 1, 'languag': 1, 'commod': 1, 'headlin': 1, 'swagger': 1, 'ooz': 1, 'opinion': 1, 'swimfan': 1, 'skim': 1, 'proof': 1, 'whiff': 1, 'coconut': 1, 'lather': 1, 'weird': 1, 'disclosur': 1, 'clair': 1, 'breastfe': 1, 'knight': 1, 'tombston': 1, 'mani': 1, 'pedi': 1, 'subtweet': 1, 'hippo': 1, 'sausag': 1, 'densiti': 1, 'disgust': 1, 'wave': 1, 'vault': 1, 'circumcis': 1, 'rival': 1, 'cornichon': 1, 'sculptor': 1, 'painter': 1, 'wine': 1, 'fascin': 1, 'pupat': 1, 'chrysali': 1, 'mirror': 1, 'whereabout': 1, 'moos': 1, 'dairi': 1, 'mustach': 1, 'graffito': 1, 'comma': 1, 'prosecut': 1, 'profil': 1, 'millionair': 1, 'exoner': 1, 'sock': 1, 'kismet': 1, 'resign': 1, 'solitud': 1, 'bull': 1, 'cart': 1, 'backlash': 1, 'inabl': 1, 'suffer': 1, 'shadow': 1, 'appoint': 1, 'rent': 1, 'latex': 1, 'cast': 1, 'orgasm': 1, 'debrief': 1, 'torso': 1, 'shrivel': 1, 'husk': 1, 'raisin': 1, 'foreplay': 1, 'vapid': 1, 'stunt': 1, 'supervis': 1, 'ouch': 1, 'plop': 1, 'privileg': 1, 'disagre': 1, 'crib': 1, 'groceri': 1, 'nurseri': 1, 'cloud': 1, 'chocolati': 1, 'delight': 1, 'circl': 1, 'fiber': 1, 'antioxid': 1, 'chit': 1, 'skedaddl': 1, 'fork': 1, 'lizard': 1, 'confirm': 1, 'loos': 1, 'acoust': 1, 'recal': 1, 'call': 1, 'reexamin': 1, 'supercool': 1, 'contend': 1, 'overlook': 1, 'dolli': 1, 'juvenil': 1, 'globe': 1, 'jewel': 1, 'gaze': 1, 'alley': 1, 'watermelon': 1, 'ador': 1, 'summertim': 1, 'slugger': 1, 'bash': 1, 'cocktail': 1, 'fundrais': 1, 'maniac': 1, 'squirrel': 1, 'sticker': 1, 'underboob': 1, 'worst': 1, 'greasi': 1, 'intrigu': 1, 'attend': 1, 'creep': 1, 'waiter': 1, 'palooza': 1, 'mannequin': 1, 'lifetim': 1, 'monkey': 1, 'tearaway': 1, 'preambl': 1, 'custodi': 1, 'chief': 1, 'withhold': 1, 'entranc': 1, 'jazz': 1, 'sprint': 1, 'mechan': 1, 'reject': 1, 'skater': 1, 'heisten': 1, 'taglin': 1, 'brawn': 1, 'paramour': 1, 'consider': 1, 'tunnel': 1, 'cologn': 1, 'pandemonium': 1, 'tweet': 1, 'forgiv': 1, 'somersault': 1, 'argument': 1, 'oppon': 1, 'overconfid': 1, 'expos': 1, 'jefford': 1, 'rendezv': 1, 'proposit': 1, 'cloak': 1, 'curv': 1, 'cockroach': 1, 'pier': 1, 'sweeti': 1, 'strip': 1, 'handlebar': 1, 'scorpion': 1, 'nest': 1, 'beverag': 1, 'fruit': 1, 'forward': 1, 'riesl': 1, 'exagger': 1, 'arous': 1, 'suspicion': 1, 'kingjakerulez': 1, 'near': 1, 'provok': 1, 'colli': 1, 'squint': 1, 'protg': 1, 'exclud': 1, 'compar': 1, 'stair': 1, 'pace': 1, 'imbecil': 1, 'athlet': 1, 'frequenc': 1, 'waffl': 1, 'xylophon': 1, 'stairwel': 1, 'lackey': 1, 'humili': 1, 'site': 1, 'queen': 1, 'pharmacist': 1, 'earshot': 1, 'adjust': 1, 'strap': 1, 'buzzer': 1, 'instal': 1, 'blaze': 1, 'assur': 1, 'checklist': 1, 'major': 1, 'communic': 1, 'agent': 1, 'squirt': 1, 'sentiment': 1, 'backbon': 1, 'shock': 1, 'bunk': 1, 'an': 1, 'claim': 1, 'fame': 1, 'invad': 1, 'stoner': 1, 'spite': 1, 'blackmail': 1, 'judg': 1, 'claw': 1, 'raccoon': 1, 'natur': 1, 'corni': 1, 'teenag': 1, 'gorilla': 1, 'siphon': 1, 'junki': 1, 'copper': 1, 'cameo': 1, 'lassi': 1, 'eeeeeee': 1, 'grace': 1, 'cousin': 1, 'fetch': 1, 'tan': 1, 'deck': 1, 'sleev': 1, 'boat': 1, 'musket': 1, 'coupon': 1, 'zipper': 1, 'excori': 1, 'golf': 1, 'stoney': 1, 'terrain': 1, 'ass': 1, 'techniqu': 1, 'injuri': 1, 'circus': 1, 'ignit': 1, 'antiqu': 1, 'berkshir': 1, 'steam': 1, 'orific': 1, 'pewwwnd': 1, 'pwne': 1, 'prof': 1, 'worm': 1, 'comrad': 1, 'weather': 1, 'whiz': 1, 'background': 1, 'logic': 1, 'brows': 1, 'shotgun': 1, 'databas': 1, 'countri': 1, 'yuck': 1, 'taint': 1, 'vape': 1, 'encamp': 1, 'askew': 1, 'registr': 1, 'newspap': 1, 'detain': 1, 'outsmart': 1, 'delay': 1, 'mankind': 1, 'mock': 1, 'shred': 1, 'document': 1, 'gravi': 1, 'cardio': 1, 'valid': 1, 'waiv': 1, 'fowl': 1, 'deer': 1, 'grous': 1, 'oversight': 1, 'contest': 1, 'inmat': 1, 'ralli': 1, 'troop': 1, 'poni': 1, 'unlock': 1, 'snort': 1, 'graph': 1, 'calcul': 1, 'bongo': 1, 'eyebal': 1, 'stage': 1, 'interven': 1, 'commit': 1, 'rescu': 1, 'madman': 1, 'breez': 1, 'even': 1, 'impal': 1, 'rifl': 1, 'sammi': 1, 'squadron': 1, 'minus': 1, 'ninja': 1, 'needl': 1, 'stool': 1, 'wretch': 1, 'exhal': 1, 'repuls': 1, 'defrost': 1, 'commonwealth': 1, 'cost': 1, 'surrend': 1, 'gooey': 1, 'wizard': 1, 'pill': 1, 'daisi': 1, 'lovebird': 1, 'civilian': 1, 'violat': 1, 'fist': 1, 'lullabi': 1, 'smorti': 1, 'mwah': 1, 'smooch': 1, 'reciproc': 1, 'blanket': 1, 'congrat': 1, 'downtown': 1, 'berri': 1, 'slushi': 1, 'swell': 1, 'possum': 1, 'kisser': 1, 'mimic': 1, 'visto': 1, 'erala': 1, 'lament': 1, 'marinara': 1, 'restaurant': 1, 'repair': 1, 'fritz': 1, 'disappear': 1, 'scrambl': 1, 'facil': 1, 'disabl': 1, 'hideout': 1, 'bandag': 1, 'memorandum': 1, 'admonish': 1, 'intervent': 1, 'retro': 1, 'chop': 1, 'brace': 1, 'haze': 1, 'australian': 1, 'demograph': 1, 'conquer': 1, 'bonzer': 1, 'hump': 1, 'chime': 1, 'brighten': 1, 'curd': 1, 'mudgeon': 1, 'stepson': 1, 'recommend': 1, 'sneaker': 1, 'playa': 1, 'burglar': 1, 'vacat': 1, 'flesh': 1, 'gendarm': 1, 'sont': 1, 'vampir': 1, 'anthem': 1, 'televis': 1, 'priorit': 1, 'massacr': 1, 'journal': 1, 'enamel': 1, 'decay': 1, 'reflux': 1, 'drongo': 1, 'mainten': 1, 'bedfellow': 1, 'limp': 1, 'bedtim': 1, 'sheet': 1, 'doodyhead': 1, 'tickler': 1, 'sail': 1, 'knot': 1, 'bowlin': 1, 'exhaust': 1, 'cri': 1, 'coast': 1, 'jungl': 1, 'subject': 1, 'hobbl': 1, 'hopper': 1, 'embrac': 1, 'compadr': 1, 'raunchi': 1, 'indec': 1, 'exercis': 1, 'cowardic': 1, 'alimoni': 1, 'tiebreak': 1, 'slit': 1, 'anus': 1, 'scrunchi': 1, 'sting': 1, 'pastri': 1, 'glue': 1, 'select': 1, 'wrench': 1, 'frickin': 1, 'hologram': 1, 'meat': 1, 'tool': 1, 'intimid': 1, 'outsid': 1, 'misread': 1, 'thang': 1, 'humbl': 1, 'helmet': 1, 'desir': 1, 'soldier': 1, 'addenda': 1, 'unleash': 1, 'jack': 1, 'bozo': 1, 'disrespect': 1, 'pinbal': 1, 'mad': 1, 'grave': 1, 'autumn': 1, 'squash': 1, 'cater': 1, 'ruse': 1, 'taco': 1, 'sunup': 1, 'cutter': 1, 'execut': 1, 'excerpt': 1, 'puff': 1, 'gait': 1, 'dirti': 1, 'sand': 1, 'hourglass': 1, 'cheddar': 1, 'coincid': 1, 'dolphin': 1, 'soap': 1, 'bowl': 1, 'mishap': 1, 'backstrok': 1, 'gram': 1, 'hummus': 1, 'segreg': 1, 'ruler': 1, 'pierogi': 1, 'superdup': 1, 'anoint': 1, 'director': 1, 'stroke': 1, 'nuditi': 1, 'rubi': 1, 'friggin': 1, 'recognit': 1, 'murmur': 1, 'basi': 1, 'empir': 1, 'timelin': 1, 'genitalia': 1, 'mommi': 1, 'dispos': 1, 'implement': 1, 'giddi': 1, 'excit': 1, 'earhol': 1, 'blacksmith': 1, 'smelter': 1, 'smelt': 1, 'oman': 1, 'birth': 1, 'sauci': 1, 'merch': 1, 'lattic': 1, 'champer': 1, 'mead': 1, 'cayenn': 1, 'hitch': 1, 'trickl': 1, 'fate': 1, 'vessel': 1, 'inflat': 1, 'marathon': 1, 'burst': 1, 'bunhead': 1, 'espresso': 1, 'raspberri': 1, 'self': 1, 'origami': 1, 'frog': 1, 'swan': 1, 'oxygen': 1, 'nozzl': 1, 'alliter': 1, 'beatnik': 1, 'frost': 1, 'bride': 1, 'meantim': 1, 'entertain': 1, 'heini': 1, 'journey': 1, 'flippiti': 1, 'flop': 1, 'sabotag': 1, 'shove': 1, 'aww': 1, 'event': 1, 'rush': 1, 'sleepless': 1, 'vindic': 1, 'infect': 1, 'yeast': 1, 'transit': 1, 'biggi': 1, 'interact': 1, 'strawberri': 1, 'suicid': 1, 'dispens': 1, 'subterfug': 1, 'discov': 1, 'zinc': 1, 'fast': 1, 'disapprov': 1, 'innit': 1, 'parlor': 1, 'sugarcoat': 1, 'heroin': 1, 'blog': 1, 'anticip': 1, 'manhunt': 1, 'trend': 1, 'skirt': 1, 'cord': 1, 'hookup': 1, 'pollen': 1, 'chart': 1, 'product': 1, 'discern': 1, 'inch': 1, 'succeed': 1, 'boil': 1, 'pinpoint': 1, 'warmth': 1, 'burp': 1, 'insati': 1, 'minx': 1, 'bestow': 1, 'wreck': 1, 'profit': 1, 'whee': 1, 'toasti': 1, 'hoagi': 1, 'mayonnais': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(count['arrest'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7MMAKhpGmFZ",
        "outputId": "328103df-b9a5-455b-baea-21a04a411b24"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp_e6ig-Gorp",
        "outputId": "8339a92b-eb68-40ba-ebab-b78df821e71b"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2859"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
        "words and how many times those words appear. Save this to 'bow_corpus'\n",
        "'''\n",
        "# TODO\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_lines]\n",
        "\n"
      ],
      "metadata": {
        "id": "Ep0LNcMJGqGo"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Checking Bag of Words corpus for our sample document --> (token_id, token_count)\n",
        "'''\n",
        "bow_corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoJh5dcgG4Hi",
        "outputId": "49f5c57a-9738-4b7c-c7c2-50c32ee909ac"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1), (1, 1), (2, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Preview BOW for our sample preprocessed document\n",
        "'''\n",
        "# Here document_num is document number 4310 which we have checked in Step 2\n",
        "bow_doc_4310 = bow_corpus[0]\n",
        "\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0],\n",
        "                                                     dictionary[bow_doc_4310[i][0]],\n",
        "                                                     bow_doc_4310[i][1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhsKdvLYHBZg",
        "outputId": "cc50a752-244f-478a-f814-5f960712a403"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 0 (\"breath\") appears 1 time.\n",
            "Word 1 (\"spend\") appears 1 time.\n",
            "Word 2 (\"year\") appears 1 time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create tf-idf model object using models.TfidfModel on 'bow_corpus' and save it to 'tfidf'\n",
        "'''\n",
        "from gensim import corpora, models\n",
        "\n",
        "# TODO\n",
        "tfidf = models.TfidfModel(bow_corpus)"
      ],
      "metadata": {
        "id": "QG4MvL_4HNCn"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Apply transformation to the entire corpus and call it 'corpus_tfidf'\n",
        "'''\n",
        "# TODO\n",
        "corpus_tfidf = tfidf[bow_corpus]"
      ],
      "metadata": {
        "id": "4dauHeG_HO-_"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Preview TF-IDF scores for our first document --> --> (token_id, tfidf score)\n",
        "'''\n",
        "from pprint import pprint\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JJ9X8xwHRX2",
        "outputId": "9ee55e60-04b0-485c-f9d0-5aa1cc805b38"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.6787707175005034), (1, 0.5562740231490745), (2, 0.47940538611220745)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lda_model = gensim.models.LdaModel(bow_corpus,\n",
        "#                                    num_topics=15,  # Changed to 15 topics\n",
        "#                                    id2word=dictionary,\n",
        "#                                    passes=50,  # Increased to 100 passes\n",
        "#                                    alpha=0.01,  # Using 'auto' for alpha #lower values means lines have fewer topics in them\n",
        "#                                    eta='auto')  # Using 'auto' for eta\n",
        "# # LDA multicore\n",
        "\n",
        "lda_model = gensim.models.LdaModel(corpus_tfidf,\n",
        "                                   num_topics=50,  # Changed to 15 topics\n",
        "                                   id2word=dictionary,\n",
        "                                   passes=50,  # Increased to 100 passes\n",
        "                                   alpha='auto',  # Using 'auto' for alpha #lower values means lines have fewer topics in them\n",
        "                                   eta='auto')  # topics have less words associated with them, Using 'auto' for eta\n",
        "# LDA multicore\n",
        "\n",
        "'''\n",
        "Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n",
        "'''\n",
        "# TODO\n",
        "#lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics = 15, id2word = dictionary, passes = 50, alpha = 'auto', eta = 'auto')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-f9oIwQ2HeO2",
        "outputId": "cf206e9a-bec9-4535-909c-781e23b8ab10"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nTrain your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "For each topic, we will explore the words occuring in that topic and its relative weight\n",
        "'''\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxw4RoXxH2jS",
        "outputId": "d24d509b-c508-45b7-da86-06355b98aed8"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.209*\"offic\" + 0.043*\"draw\" + 0.040*\"copi\" + 0.019*\"purpos\" + 0.000*\"spread\" + 0.000*\"pant\" + 0.000*\"truce\" + 0.000*\"ghost\" + 0.000*\"faton\" + 0.000*\"name\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.147*\"crime\" + 0.064*\"scene\" + 0.025*\"jurisdict\" + 0.023*\"press\" + 0.021*\"elev\" + 0.018*\"bump\" + 0.011*\"disrupt\" + 0.000*\"alter\" + 0.000*\"pant\" + 0.000*\"spread\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.126*\"hous\" + 0.053*\"closet\" + 0.042*\"replac\" + 0.040*\"note\" + 0.004*\"tissu\" + 0.004*\"cedar\" + 0.000*\"steal\" + 0.000*\"faton\" + 0.000*\"pant\" + 0.000*\"ghost\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.332*\"stop\" + 0.117*\"detect\" + 0.070*\"book\" + 0.027*\"blood\" + 0.009*\"boot\" + 0.003*\"mobster\" + 0.003*\"wipe\" + 0.000*\"spread\" + 0.000*\"pant\" + 0.000*\"timberlak\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.199*\"walk\" + 0.099*\"stand\" + 0.098*\"polic\" + 0.067*\"joke\" + 0.027*\"caus\" + 0.024*\"janitor\" + 0.022*\"fail\" + 0.020*\"design\" + 0.018*\"fridg\" + 0.012*\"threaten\"\n",
            "\n",
            "\n",
            "Topic: 5 \n",
            "Words: 0.295*\"know\" + 0.170*\"come\" + 0.144*\"tell\" + 0.049*\"like\" + 0.039*\"believ\" + 0.031*\"bring\" + 0.030*\"minut\" + 0.018*\"rule\" + 0.016*\"steal\" + 0.014*\"sell\"\n",
            "\n",
            "\n",
            "Topic: 6 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 7 \n",
            "Words: 0.164*\"tonight\" + 0.128*\"break\" + 0.111*\"drink\" + 0.107*\"order\" + 0.042*\"costum\" + 0.031*\"involv\" + 0.015*\"bottl\" + 0.011*\"disobey\" + 0.008*\"overstep\" + 0.005*\"contain\"\n",
            "\n",
            "\n",
            "Topic: 8 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 9 \n",
            "Words: 0.138*\"lock\" + 0.087*\"person\" + 0.081*\"crap\" + 0.073*\"bathroom\" + 0.035*\"cabinet\" + 0.027*\"wonder\" + 0.011*\"combin\" + 0.011*\"justic\" + 0.010*\"insur\" + 0.009*\"fraud\"\n",
            "\n",
            "\n",
            "Topic: 10 \n",
            "Words: 0.115*\"world\" + 0.034*\"lover\" + 0.027*\"spider\" + 0.015*\"hallway\" + 0.000*\"alter\" + 0.000*\"timberlak\" + 0.000*\"name\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"faton\"\n",
            "\n",
            "\n",
            "Topic: 11 \n",
            "Words: 0.215*\"look\" + 0.167*\"talk\" + 0.137*\"thing\" + 0.046*\"read\" + 0.044*\"sign\" + 0.036*\"murder\" + 0.033*\"stuff\" + 0.033*\"send\" + 0.024*\"chanc\" + 0.015*\"line\"\n",
            "\n",
            "\n",
            "Topic: 12 \n",
            "Words: 0.186*\"want\" + 0.116*\"happen\" + 0.056*\"stay\" + 0.056*\"life\" + 0.051*\"word\" + 0.049*\"care\" + 0.042*\"solv\" + 0.040*\"money\" + 0.036*\"pizza\" + 0.031*\"pull\"\n",
            "\n",
            "\n",
            "Topic: 13 \n",
            "Words: 0.159*\"follow\" + 0.062*\"dude\" + 0.017*\"wash\" + 0.000*\"timberlak\" + 0.000*\"name\" + 0.000*\"alter\" + 0.000*\"spread\" + 0.000*\"faton\" + 0.000*\"shampoo\" + 0.000*\"sucker\"\n",
            "\n",
            "\n",
            "Topic: 14 \n",
            "Words: 0.184*\"place\" + 0.159*\"shoot\" + 0.083*\"drug\" + 0.079*\"pick\" + 0.061*\"bust\" + 0.051*\"finger\" + 0.004*\"flinch\" + 0.002*\"rican\" + 0.000*\"timberlak\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 15 \n",
            "Words: 0.282*\"thank\" + 0.196*\"need\" + 0.083*\"arrest\" + 0.058*\"reason\" + 0.028*\"hang\" + 0.024*\"wast\" + 0.023*\"weapon\" + 0.022*\"paint\" + 0.014*\"cloth\" + 0.010*\"knife\"\n",
            "\n",
            "\n",
            "Topic: 16 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 17 \n",
            "Words: 0.150*\"year\" + 0.126*\"babi\" + 0.105*\"girl\" + 0.071*\"wife\" + 0.037*\"photo\" + 0.026*\"wallet\" + 0.013*\"mother\" + 0.007*\"crispi\" + 0.007*\"handwrit\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 18 \n",
            "Words: 0.222*\"start\" + 0.079*\"play\" + 0.061*\"choos\" + 0.051*\"mission\" + 0.045*\"track\" + 0.020*\"music\" + 0.019*\"accept\" + 0.013*\"click\" + 0.000*\"sucker\" + 0.000*\"ship\"\n",
            "\n",
            "\n",
            "Topic: 19 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 20 \n",
            "Words: 0.057*\"jump\" + 0.019*\"enter\" + 0.015*\"coma\" + 0.000*\"pant\" + 0.000*\"alter\" + 0.000*\"timberlak\" + 0.000*\"ghost\" + 0.000*\"faton\" + 0.000*\"brake\" + 0.000*\"name\"\n",
            "\n",
            "\n",
            "Topic: 21 \n",
            "Words: 0.163*\"turn\" + 0.139*\"problem\" + 0.094*\"today\" + 0.087*\"idea\" + 0.044*\"burn\" + 0.039*\"present\" + 0.023*\"danc\" + 0.018*\"tabl\" + 0.015*\"child\" + 0.011*\"sneak\"\n",
            "\n",
            "\n",
            "Topic: 22 \n",
            "Words: 0.073*\"sergeant\" + 0.073*\"garbag\" + 0.070*\"prove\" + 0.069*\"evid\" + 0.058*\"hope\" + 0.048*\"chang\" + 0.045*\"write\" + 0.043*\"pictur\" + 0.030*\"distract\" + 0.026*\"troubl\"\n",
            "\n",
            "\n",
            "Topic: 23 \n",
            "Words: 0.179*\"hour\" + 0.076*\"close\" + 0.062*\"floor\" + 0.054*\"paperwork\" + 0.046*\"piec\" + 0.037*\"tomorrow\" + 0.035*\"screw\" + 0.024*\"wheel\" + 0.021*\"defeat\" + 0.006*\"destroy\"\n",
            "\n",
            "\n",
            "Topic: 24 \n",
            "Words: 0.204*\"night\" + 0.121*\"desk\" + 0.095*\"file\" + 0.036*\"fall\" + 0.035*\"rock\" + 0.025*\"text\" + 0.018*\"pile\" + 0.014*\"subway\" + 0.007*\"chicken\" + 0.007*\"stack\"\n",
            "\n",
            "\n",
            "Topic: 25 \n",
            "Words: 0.446*\"love\" + 0.040*\"apart\" + 0.020*\"peni\" + 0.012*\"prank\" + 0.000*\"alter\" + 0.000*\"spread\" + 0.000*\"truce\" + 0.000*\"pant\" + 0.000*\"sucker\" + 0.000*\"name\"\n",
            "\n",
            "\n",
            "Topic: 26 \n",
            "Words: 0.135*\"second\" + 0.092*\"husband\" + 0.022*\"scream\" + 0.015*\"role\" + 0.000*\"pant\" + 0.000*\"timberlak\" + 0.000*\"spread\" + 0.000*\"name\" + 0.000*\"alter\" + 0.000*\"faton\"\n",
            "\n",
            "\n",
            "Topic: 27 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 28 \n",
            "Words: 0.271*\"mean\" + 0.159*\"guess\" + 0.145*\"hear\" + 0.039*\"save\" + 0.033*\"bird\" + 0.033*\"dinner\" + 0.026*\"coupl\" + 0.018*\"offer\" + 0.000*\"spread\" + 0.000*\"timberlak\"\n",
            "\n",
            "\n",
            "Topic: 29 \n",
            "Words: 0.187*\"meet\" + 0.075*\"mayor\" + 0.055*\"right\" + 0.041*\"artist\" + 0.031*\"brother\" + 0.029*\"purs\" + 0.027*\"film\" + 0.003*\"eyewit\" + 0.000*\"ghost\" + 0.000*\"sucker\"\n",
            "\n",
            "\n",
            "Topic: 30 \n",
            "Words: 0.140*\"catch\" + 0.106*\"head\" + 0.096*\"boss\" + 0.048*\"fountain\" + 0.047*\"machin\" + 0.043*\"beat\" + 0.018*\"cheek\" + 0.003*\"cave\" + 0.000*\"pant\" + 0.000*\"faton\"\n",
            "\n",
            "\n",
            "Topic: 31 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 32 \n",
            "Words: 0.136*\"figur\" + 0.134*\"face\" + 0.077*\"video\" + 0.059*\"camera\" + 0.057*\"record\" + 0.015*\"screen\" + 0.000*\"pant\" + 0.000*\"ghost\" + 0.000*\"spread\" + 0.000*\"brake\"\n",
            "\n",
            "\n",
            "Topic: 33 \n",
            "Words: 0.154*\"help\" + 0.137*\"leav\" + 0.101*\"foot\" + 0.070*\"question\" + 0.067*\"excus\" + 0.053*\"miss\" + 0.041*\"touch\" + 0.035*\"open\" + 0.024*\"answer\" + 0.021*\"luck\"\n",
            "\n",
            "\n",
            "Topic: 34 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 35 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 36 \n",
            "Words: 0.275*\"time\" + 0.158*\"shut\" + 0.077*\"butt\" + 0.063*\"captain\" + 0.050*\"check\" + 0.018*\"home\" + 0.017*\"issu\" + 0.015*\"daddi\" + 0.014*\"custom\" + 0.012*\"jerk\"\n",
            "\n",
            "\n",
            "Topic: 37 \n",
            "Words: 0.217*\"wanna\" + 0.125*\"room\" + 0.040*\"paper\" + 0.012*\"zone\" + 0.000*\"name\" + 0.000*\"alter\" + 0.000*\"timberlak\" + 0.000*\"faton\" + 0.000*\"spread\" + 0.000*\"propos\"\n",
            "\n",
            "\n",
            "Topic: 38 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 39 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 40 \n",
            "Words: 0.262*\"hand\" + 0.118*\"report\" + 0.100*\"ladi\" + 0.053*\"morn\" + 0.016*\"road\" + 0.016*\"race\" + 0.013*\"match\" + 0.009*\"grandma\" + 0.005*\"bagel\" + 0.004*\"grandson\"\n",
            "\n",
            "\n",
            "Topic: 41 \n",
            "Words: 0.189*\"feel\" + 0.158*\"plan\" + 0.055*\"mind\" + 0.049*\"smile\" + 0.041*\"inspir\" + 0.032*\"decis\" + 0.031*\"charg\" + 0.024*\"breath\" + 0.019*\"brain\" + 0.016*\"assign\"\n",
            "\n",
            "\n",
            "Topic: 42 \n",
            "Words: 0.330*\"work\" + 0.128*\"wed\" + 0.062*\"month\" + 0.050*\"precinct\" + 0.046*\"number\" + 0.033*\"realiz\" + 0.031*\"ring\" + 0.019*\"wall\" + 0.008*\"muscl\" + 0.006*\"station\"\n",
            "\n",
            "\n",
            "Topic: 43 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 44 \n",
            "Words: 0.000*\"spread\" + 0.000*\"ghost\" + 0.000*\"feud\" + 0.000*\"propos\" + 0.000*\"truce\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"timberlak\" + 0.000*\"alter\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 45 \n",
            "Words: 0.163*\"speech\" + 0.062*\"sens\" + 0.022*\"shame\" + 0.015*\"teamwork\" + 0.010*\"appeal\" + 0.004*\"rous\" + 0.004*\"camraderi\" + 0.000*\"pant\" + 0.000*\"faton\" + 0.000*\"truce\"\n",
            "\n",
            "\n",
            "Topic: 46 \n",
            "Words: 0.453*\"think\" + 0.098*\"case\" + 0.086*\"peopl\" + 0.073*\"hate\" + 0.058*\"point\" + 0.000*\"truce\" + 0.000*\"faton\" + 0.000*\"doom\" + 0.000*\"alter\" + 0.000*\"name\"\n",
            "\n",
            "\n",
            "Topic: 47 \n",
            "Words: 0.115*\"friend\" + 0.114*\"wear\" + 0.093*\"woman\" + 0.069*\"mouth\" + 0.052*\"shirt\" + 0.051*\"food\" + 0.020*\"salmon\" + 0.013*\"wit\" + 0.008*\"poison\" + 0.000*\"sucker\"\n",
            "\n",
            "\n",
            "Topic: 48 \n",
            "Words: 0.147*\"listen\" + 0.117*\"watch\" + 0.078*\"street\" + 0.068*\"throw\" + 0.056*\"learn\" + 0.044*\"jail\" + 0.000*\"spread\" + 0.000*\"name\" + 0.000*\"faton\" + 0.000*\"pant\"\n",
            "\n",
            "\n",
            "Topic: 49 \n",
            "Words: 0.443*\"wait\" + 0.121*\"hold\" + 0.014*\"bear\" + 0.012*\"inform\" + 0.010*\"appear\" + 0.000*\"rain\" + 0.000*\"faton\" + 0.000*\"shampoo\" + 0.000*\"pant\" + 0.000*\"timberlak\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Define lda model using corpus_tfidf, again using gensim.models.LdaMulticore()\n",
        "'''\n",
        "# TODO\n",
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics = 10, id2word = dictionary, passes = 50)\n"
      ],
      "metadata": {
        "id": "-41inLvTISLX"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "For each topic, we will explore the words occuring in that topic and its relative weight\n",
        "'''\n",
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print(\"Topic: {} \\nWord: {}\".format(idx, topic))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "ksizQTfiPT_P",
        "outputId": "f9894780-9b9d-4631-daff-827ae3ac5f83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Word: 0.061*\"okay\" + 0.016*\"know\" + 0.012*\"kid\" + 0.010*\"say\" + 0.009*\"gina\" + 0.009*\"hate\" + 0.008*\"detect\" + 0.008*\"terribl\" + 0.007*\"gonna\" + 0.007*\"sorri\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Word: 0.014*\"talk\" + 0.011*\"guy\" + 0.009*\"news\" + 0.008*\"vultur\" + 0.008*\"good\" + 0.007*\"head\" + 0.007*\"sound\" + 0.007*\"ask\" + 0.006*\"precinct\" + 0.006*\"terri\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Word: 0.025*\"thank\" + 0.014*\"tell\" + 0.012*\"mean\" + 0.011*\"best\" + 0.011*\"cool\" + 0.008*\"stop\" + 0.008*\"weird\" + 0.007*\"believ\" + 0.007*\"damn\" + 0.007*\"amaz\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Word: 0.014*\"want\" + 0.014*\"help\" + 0.011*\"break\" + 0.009*\"wrong\" + 0.008*\"ropesburg\" + 0.008*\"shoot\" + 0.007*\"tire\" + 0.007*\"nervous\" + 0.007*\"wanna\" + 0.007*\"think\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Word: 0.044*\"yeah\" + 0.017*\"like\" + 0.013*\"rosa\" + 0.012*\"date\" + 0.012*\"time\" + 0.012*\"santiago\" + 0.011*\"happen\" + 0.010*\"look\" + 0.009*\"sorri\" + 0.008*\"know\"\n",
            "\n",
            "\n",
            "Topic: 5 \n",
            "Word: 0.018*\"peralta\" + 0.017*\"go\" + 0.013*\"thing\" + 0.013*\"work\" + 0.011*\"hear\" + 0.010*\"jake\" + 0.009*\"laugh\" + 0.009*\"arrest\" + 0.009*\"hello\" + 0.008*\"diaz\"\n",
            "\n",
            "\n",
            "Topic: 6 \n",
            "Word: 0.038*\"right\" + 0.012*\"fine\" + 0.012*\"nice\" + 0.009*\"minut\" + 0.009*\"dead\" + 0.008*\"whitman\" + 0.008*\"peralta\" + 0.006*\"shut\" + 0.006*\"room\" + 0.006*\"make\"\n",
            "\n",
            "\n",
            "Topic: 7 \n",
            "Word: 0.015*\"captain\" + 0.011*\"charl\" + 0.010*\"love\" + 0.008*\"leav\" + 0.006*\"world\" + 0.006*\"mayb\" + 0.006*\"paperwork\" + 0.006*\"late\" + 0.005*\"like\" + 0.005*\"offic\"\n",
            "\n",
            "\n",
            "Topic: 8 \n",
            "Word: 0.023*\"come\" + 0.011*\"gonna\" + 0.008*\"safe\" + 0.007*\"hell\" + 0.006*\"shirt\" + 0.006*\"wish\" + 0.006*\"follow\" + 0.005*\"need\" + 0.005*\"great\" + 0.005*\"interest\"\n",
            "\n",
            "\n",
            "Topic: 9 \n",
            "Word: 0.029*\"good\" + 0.016*\"boyl\" + 0.011*\"know\" + 0.011*\"think\" + 0.008*\"sure\" + 0.008*\"slump\" + 0.007*\"murder\" + 0.007*\"turn\" + 0.007*\"care\" + 0.007*\"right\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}